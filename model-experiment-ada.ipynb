{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:16:54.785680Z","iopub.execute_input":"2025-04-27T19:16:54.786512Z","iopub.status.idle":"2025-04-27T19:16:54.854154Z","shell.execute_reply.started":"2025-04-27T19:16:54.786462Z","shell.execute_reply":"2025-04-27T19:16:54.852883Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install --upgrade scikit-learn==1.3.2 imbalanced-learn==0.11.0\nimport sklearn\nprint(\"Version:\", sklearn.__version__)\nprint(\"Location:\", sklearn.__file__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install dagshub mlflow\nimport dagshub\nimport mlflow\ndagshub.init(repo_owner='dimna21', repo_name='ML_Assignment2', mlflow=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"identity_train = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntransaction_train = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:18:24.157448Z","iopub.execute_input":"2025-04-27T19:18:24.157791Z","iopub.status.idle":"2025-04-27T19:18:55.612160Z","shell.execute_reply.started":"2025-04-27T19:18:24.157746Z","shell.execute_reply":"2025-04-27T19:18:55.611215Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def print_stats(df):\n    print('Columns:')\n    print(df.columns)\n    print('----------------------------')\n    print(f'Missing counts:')\n    print(df.isna().sum())\n    print('----------------------------')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:23:16.536347Z","iopub.execute_input":"2025-04-14T19:23:16.536714Z","iopub.status.idle":"2025-04-14T19:23:16.542604Z","shell.execute_reply.started":"2025-04-14T19:23:16.536682Z","shell.execute_reply":"2025-04-14T19:23:16.541549Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print_stats(transaction_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_stats(identity_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(transaction_train.shape)\nprint(identity_train.shape)\nprint(transaction_test.shape)\nprint(identity_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:23:31.698308Z","iopub.execute_input":"2025-04-14T19:23:31.698629Z","iopub.status.idle":"2025-04-14T19:23:31.704719Z","shell.execute_reply.started":"2025-04-14T19:23:31.698595Z","shell.execute_reply":"2025-04-14T19:23:31.703300Z"}},"outputs":[{"name":"stdout","text":"(590540, 394)\n(144233, 41)\n(506691, 393)\n(141907, 41)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"df = transaction_train.merge(identity_train, on='TransactionID', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:21:00.680828Z","iopub.execute_input":"2025-04-27T19:21:00.681171Z","iopub.status.idle":"2025-04-27T19:21:01.843283Z","shell.execute_reply.started":"2025-04-27T19:21:00.681141Z","shell.execute_reply":"2025-04-27T19:21:01.842312Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"bad_cols = ['id_33','id_31','id_30','P_emaildomain','R_emaildomain', 'DeviceInfo']\ncat_cols = [col for col in df.columns if df[col].dtype == 'object' and col not in bad_cols]\nnum_cols = [col for col in df.columns if df[col].dtype != 'object' and col not in ['TransactionID', 'TransactionDT','isFraud']]\n\nprint(len(cat_cols))\nprint(len(num_cols))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T19:21:04.959897Z","iopub.execute_input":"2025-04-27T19:21:04.960235Z","iopub.status.idle":"2025-04-27T19:21:04.981190Z","shell.execute_reply.started":"2025-04-27T19:21:04.960206Z","shell.execute_reply":"2025-04-27T19:21:04.979930Z"}},"outputs":[{"name":"stdout","text":"25\n400\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Undersampling","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\n\nX = df.drop(columns='isFraud')\ny = df['isFraud']\n\nrus = RandomUnderSampler(sampling_strategy=0.3, random_state=42)\nX_resampled, y_resampled = rus.fit_resample(X, y)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:52:20.951220Z","iopub.execute_input":"2025-04-27T20:52:20.951670Z","iopub.status.idle":"2025-04-27T20:52:23.549872Z","shell.execute_reply.started":"2025-04-27T20:52:20.951632Z","shell.execute_reply":"2025-04-27T20:52:23.548518Z"}},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":"# NA filler","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass NAfiller(BaseEstimator, TransformerMixin):\n    def __init__(self, cat_cols, num_cols):\n        self.cat_cols = cat_cols\n        self.num_cols = num_cols\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X_copy = X.copy()\n        #drop bad columns before encoding\n        X_copy.drop(['id_33','id_31','id_30','P_emaildomain','R_emaildomain', 'DeviceInfo','TransactionID', 'TransactionDT'], axis=1, inplace=True)\n        for cat in self.cat_cols:\n            X_copy[cat] = X_copy[cat].fillna(f'no_{cat}')\n        for num in self.num_cols:\n            X_copy[num] = X_copy[num].fillna(0)\n        return X_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:52:29.692452Z","iopub.execute_input":"2025-04-27T20:52:29.692817Z","iopub.status.idle":"2025-04-27T20:52:29.700687Z","shell.execute_reply.started":"2025-04-27T20:52:29.692792Z","shell.execute_reply":"2025-04-27T20:52:29.699269Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"na_filler = NAfiller(cat_cols, num_cols)\nX_train = na_filler.fit_transform(X_train)\nX_train.isna().sum().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:52:35.023920Z","iopub.execute_input":"2025-04-27T20:52:35.024305Z","iopub.status.idle":"2025-04-27T20:52:36.146606Z","shell.execute_reply.started":"2025-04-27T20:52:35.024258Z","shell.execute_reply":"2025-04-27T20:52:36.145235Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":78},{"cell_type":"markdown","source":"# WOE mappings","metadata":{}},{"cell_type":"code","source":"na_filler = NAfiller(cat_cols, num_cols)\ndf_filled = na_filler.transform(X_resampled)\nwoe_mappings = {}\n\nfor category in cat_cols:\n    category_mapping = {}\n    distinct_values = df_filled[category].unique()\n    \n    total_positive = y_resampled[y_resampled == 1].shape[0]\n    total_negative = y_resampled[y_resampled == 0].shape[0]\n    \n    for value in distinct_values:\n        times_positive = X_resampled[(X_resampled[category] == value) & (y_resampled == 1)].shape[0] + 1\n        times_negative = X_resampled[(X_resampled[category] == value) & (y_resampled == 0)].shape[0] + 1\n        \n        weight = np.log((times_positive / total_positive) / (times_negative / total_negative))\n        category_mapping[value] = weight\n        \n    woe_mappings[category] = category_mapping\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:56:10.505931Z","iopub.execute_input":"2025-04-27T20:56:10.506286Z","iopub.status.idle":"2025-04-27T20:56:17.098642Z","shell.execute_reply.started":"2025-04-27T20:56:10.506259Z","shell.execute_reply":"2025-04-27T20:56:17.097208Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport mlflow\n\nclass WoeEncoder(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, woe_mappings):\n        self.woe_mappings = woe_mappings\n        \n    def fit(self, X, y=None):\n\n        mlflow.log_dict(self.woe_mappings, artifact_file=\"woe_mappings.json\")\n\n        return self\n    \n    def transform(self, X):\n        X_copy = X.copy()\n        for col in self.woe_mappings:\n            mapping = self.woe_mappings[col]\n            X_copy[col] = X_copy[col].replace(mapping)\n        return X_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:56:24.963847Z","iopub.execute_input":"2025-04-27T20:56:24.964231Z","iopub.status.idle":"2025-04-27T20:56:24.971721Z","shell.execute_reply.started":"2025-04-27T20:56:24.964204Z","shell.execute_reply":"2025-04-27T20:56:24.970681Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"encoder = WoeEncoder(woe_mappings)\nX_train = encoder.fit_transform(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:56:27.806281Z","iopub.execute_input":"2025-04-27T20:56:27.806646Z","iopub.status.idle":"2025-04-27T20:56:29.073585Z","shell.execute_reply.started":"2025-04-27T20:56:27.806622Z","shell.execute_reply":"2025-04-27T20:56:29.072567Z"}},"outputs":[{"name":"stderr","text":"Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","output_type":"stream"}],"execution_count":83},{"cell_type":"markdown","source":"# Correlation filter","metadata":{}},{"cell_type":"code","source":"threshold=0.8\ncorr_matrix = X_train.corr().abs()\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\nhigh_corr_pairs = []\n\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i + 1, len(corr_matrix.columns)):\n        if corr_matrix.iloc[i, j] > threshold:\n            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n\nfeatures_to_drop = []\n\nfor feat1, feat2, _ in high_corr_pairs:\n    if abs(X_train[feat1].corr(y)) < abs(X_train[feat2].corr(y_train)):\n        features_to_drop.append(feat1)\n    else:\n        features_to_drop.append(feat2)\n\nfeatures_to_drop = list(set(features_to_drop))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:56:32.490316Z","iopub.execute_input":"2025-04-27T20:56:32.490697Z","iopub.status.idle":"2025-04-27T20:58:16.688551Z","shell.execute_reply.started":"2025-04-27T20:56:32.490672Z","shell.execute_reply":"2025-04-27T20:58:16.687279Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"class CorrelationFilter(BaseEstimator, TransformerMixin):\n    def __init__(self, features_to_drop):\n        self.threshold = 0.8\n        self.features_to_drop = features_to_drop\n\n    def fit(self, X, y=None):\n        mlflow.log_dict({\"features_to_drop\": self.features_to_drop}, artifact_file=\"features_to_drop.json\")\n        return self\n\n    def transform(self, X):\n        return X.drop(columns=self.features_to_drop)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:59:15.541607Z","iopub.execute_input":"2025-04-27T20:59:15.541971Z","iopub.status.idle":"2025-04-27T20:59:15.548368Z","shell.execute_reply.started":"2025-04-27T20:59:15.541947Z","shell.execute_reply":"2025-04-27T20:59:15.547041Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"corr_filt = CorrelationFilter(features_to_drop)\nX_train = corr_filt.fit_transform(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T20:59:17.965353Z","iopub.execute_input":"2025-04-27T20:59:17.965690Z","iopub.status.idle":"2025-04-27T20:59:18.244978Z","shell.execute_reply.started":"2025-04-27T20:59:17.965666Z","shell.execute_reply":"2025-04-27T20:59:18.243663Z"}},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"# RFE","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.feature_selection import RFE\n\nestimator = XGBRegressor(\n    n_estimators=200,\n    max_depth=8,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    n_jobs=-1,\n    random_state=42,\n    verbosity=0\n)\n\nrfe = RFE(estimator=estimator, n_features_to_select=100)\nrfe.fit(X_train, y_train)\n\nselected_features = X_train.columns[rfe.support_].tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FeatureSelectorRFE(BaseEstimator, TransformerMixin):\n    def __init__(self, selected_features):\n        self.selected_features = selected_features\n\n    def fit(self, X, y=None):\n        mlflow.log_dict({\"selected_features\": self.selected_features}, artifact_file=\"selected_features.json\")\n        return self\n\n    def transform(self, X):\n        return X[self.selected_features]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:02:38.369215Z","iopub.execute_input":"2025-04-27T21:02:38.369599Z","iopub.status.idle":"2025-04-27T21:02:38.375906Z","shell.execute_reply.started":"2025-04-27T21:02:38.369576Z","shell.execute_reply":"2025-04-27T21:02:38.374704Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"rfe = FeatureSelectorRFE(selected_features)\nX_train = rfe.fit_transform(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T21:02:40.094186Z","iopub.execute_input":"2025-04-27T21:02:40.094600Z","iopub.status.idle":"2025-04-27T21:02:40.364345Z","shell.execute_reply.started":"2025-04-27T21:02:40.094576Z","shell.execute_reply":"2025-04-27T21:02:40.363369Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"import shap\nimport tempfile\nfrom sklearn.metrics import (\n    precision_score, recall_score, f1_score,\n    precision_recall_curve, roc_auc_score, roc_curve, confusion_matrix\n)\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport mlflow.sklearn\nimport os\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport shap\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n)\n\nmlflow.set_experiment(\"iter_2\")\nT = 0.5  # Prediction threshold\n\n# Imbalanced pipeline with RandomUnderSampler\nimb_pipeline = ImbPipeline([\n    ('undersampler', RandomUnderSampler(random_state=42, sampling_strategy=0.3)),\n    ('na_fill', NAfiller(cat_cols=cat_cols, num_cols=num_cols)),\n    ('woe', WoeEncoder(woe_mappings=woe_mappings)),\n    ('corr_filter', CorrelationFilter(features_to_drop=features_to_drop)),\n    ('feature_select', FeatureSelectorRFE(selected_features=selected_features)),\n    \n    ('clf', AdaBoostClassifier(\n    base_estimator=DecisionTreeClassifier(max_depth=1),\n    n_estimators=1500, \n    learning_rate=1.5,\n    random_state=42\n    ))\n\n])\n\nwith mlflow.start_run(run_name=\"iter2_AdaBoost6\", nested=True) as run:\n    imb_pipeline.fit(X_train, y_train)\n\n    mlflow.sklearn.log_model(imb_pipeline, \"model\")\n    ada_model = imb_pipeline.named_steps[\"clf\"]\n    mlflow.log_params({\n        \"sampling_strategy\": 0.3,\n        \"n_estimators\": ada_model.n_estimators,\n        \"learning_rate\": ada_model.learning_rate,\n        \"random_state\": ada_model.random_state,\n    })\n\n    def log_metrics_and_curves(X, y, split, threshold=0.25):\n        probas = imb_pipeline.predict_proba(X)[:, 1]\n        preds = (probas >= threshold).astype(int)\n\n        prec = precision_score(y, preds)\n        rec = recall_score(y, preds)\n        f1 = f1_score(y, preds)\n        auc = roc_auc_score(y, probas)\n\n        mlflow.log_metrics({\n            f\"{split}_precision\": prec,\n            f\"{split}_recall\": rec,\n            f\"{split}_f1_score\": f1,\n            f\"{split}_auc\": auc,\n            f\"{split}_threshold\": T\n        })\n\n        # Precision-Recall curve\n        precs, recalls, _ = precision_recall_curve(y, probas)\n        plt.figure()\n        plt.plot(recalls, precs, label=\"PR Curve\")\n        plt.axvline(x=rec, linestyle='--', color='r', label=f\"Recall@thresh={rec:.2f}\")\n        plt.xlabel(\"Recall\")\n        plt.ylabel(\"Precision\")\n        plt.title(f\"{split.capitalize()} Precision-Recall Curve\")\n        plt.legend()\n        pr_path = f\"{split}_pr_curve.png\"\n        plt.savefig(pr_path)\n        plt.close()\n        mlflow.log_artifact(pr_path)\n\n        # ROC curve\n        fpr, tpr, _ = roc_curve(y, probas)\n        plt.figure()\n        plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n        plt.plot([0, 1], [0, 1], linestyle='--')\n        plt.xlabel(\"False Positive Rate\")\n        plt.ylabel(\"True Positive Rate\")\n        plt.title(f\"{split.capitalize()} ROC Curve\")\n        plt.legend()\n        roc_path = f\"{split}_roc_curve.png\"\n        plt.savefig(roc_path)\n        plt.close()\n        mlflow.log_artifact(roc_path)\n\n        # Confusion matrix\n        cm = confusion_matrix(y, preds)\n        plt.figure(figsize=(6, 6))\n        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n        plt.title(f\"{split.capitalize()} Confusion Matrix\")\n        plt.colorbar()\n        tick_marks = range(2)\n        plt.xticks(tick_marks, [\"Non-Fraud\", \"Fraud\"])\n        plt.yticks(tick_marks, [\"Non-Fraud\", \"Fraud\"])\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        \n        # Plot the numbers inside the matrix\n        thresh = cm.max() / 2.\n        for i in range(cm.shape[0]):\n            for j in range(cm.shape[1]):\n                plt.text(j, i, format(cm[i, j], 'd'),\n                         horizontalalignment=\"center\",\n                         color=\"white\" if cm[i, j] > thresh else \"black\",\n                         fontsize=16)\n\n        cm_path = f\"{split}_confusion_matrix.png\"\n        plt.savefig(cm_path)\n        plt.close()\n        mlflow.log_artifact(cm_path)\n\n\n    # Log train and test metrics\n    log_metrics_and_curves(X_train, y_train, split=\"train\", threshold=T)\n    log_metrics_and_curves(X_test, y_test, split=\"test\", threshold=T)\n    print(f\"Run ID: {run.info.run_id}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T23:13:44.773463Z","iopub.execute_input":"2025-04-27T23:13:44.773923Z","iopub.status.idle":"2025-04-27T23:18:35.048133Z","shell.execute_reply.started":"2025-04-27T23:13:44.773892Z","shell.execute_reply":"2025-04-27T23:18:35.046823Z"}},"outputs":[{"name":"stderr","text":"Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n`base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n\u001b[31m2025/04/27 23:17:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\nDowncasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\nDowncasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","output_type":"stream"},{"name":"stdout","text":"Run ID: e0ad2a58e3ae4b09a5650d483573a33e\n🏃 View run iter2_AdaBoost6 at: https://dagshub.com/dimna21/ML_Assignment2.mlflow/#/experiments/15/runs/e0ad2a58e3ae4b09a5650d483573a33e\n🧪 View experiment at: https://dagshub.com/dimna21/ML_Assignment2.mlflow/#/experiments/15\n","output_type":"stream"}],"execution_count":123},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}